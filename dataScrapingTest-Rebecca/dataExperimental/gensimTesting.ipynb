{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First import data and filter to the 'text' column\n",
    "import pandas as pd\n",
    "\n",
    "#all years\n",
    "data = pd.read_json('test.json')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "##Data cleaning\n",
    "df['text'] = df['text'].astype(str).replace(r'\\\\n',' ', regex=True)\n",
    "df['text'] = df['text'].astype(str).replace(r'<','', regex=True)\n",
    "df['text'] = df['text'].astype(str).replace(r'>','', regex=True)\n",
    "df['text'] = df['text'].astype(str).replace(r'. ',' ', regex=True)\n",
    "df['text'] = df['text'].astype(str).replace(r'\\[','', regex=True)\n",
    "df['text'] = df['text'].astype(str).replace(r'\\]','', regex=True)\n",
    "df['text'] = df['text'].astype(str).replace(r'\\'','', regex=True)\n",
    "\n",
    "textsAll = df['text']\n",
    "\n",
    "#young years\n",
    "youth = \"1869, 1870, 1871, 1872, 1873, 1874, 1875\"\n",
    "df_youth = df[df['year']<=1875]\n",
    "\n",
    "\n",
    "#turning point\n",
    "turningP = \"1876, 1877, 1878\"\n",
    "\n",
    "\n",
    "#maturity\n",
    "mature = \"1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888\"\n",
    "df_mature = df[df['year']>=1879]\n",
    "\n",
    "df_mature.to_csv('df_mature.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = data['text']\n",
    "\n",
    "from pprint import pprint #pretty-printer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#remove common words\n",
    "stoplist = stopwords.words('german')\n",
    "#additional stopwords\n",
    "stopwords_new = ['.', 'ii.']\n",
    "stoplist.append(stopwords_new) #if I need to add more stopwords manually\n",
    "\n",
    "#tokenize\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist] \n",
    "    for document in documents\n",
    "]\n",
    "\n",
    "#remove words that appear only once\n",
    "\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('/tmp/document1.dict')\n",
    "\n",
    "# dictionary.token2id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x7f840cba6be0>"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "from gensim.test.utils import get_tmpfile\n",
    "fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "\n",
    "model.save(fname)\n",
    "model = Doc2Vec.load(fname)\n",
    "\n",
    "model\n",
    "# common_texts = [] # initialise empty list\n",
    "# for ind, row in df.iteritem():\n",
    "#     text = row[name_column_with_text]\n",
    "#     common_texts.append(text)\n",
    "\n",
    "\n",
    "# common_dictionary = Dictionary(common_texts)\n",
    "# common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]\n",
    "\n",
    "# lda = LdaModel(common_corpus, num_topics=10)\n",
    "\n",
    "# model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "# model.build_vocab(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}